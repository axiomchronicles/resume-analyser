# ğŸ§  Resume eâ€‘Filing 2.0 â€“ AIâ€‘Powered Resume Analyzer

An endâ€‘toâ€‘end **AI Resume Analyzer** that:

- Extracts text from **PDF resumes** or plain text  
- Cleans and analyzes the content using **NLP**  
- Computes an **ATSâ€‘style score** (0â€“100)  
- Detects **weak phrases** and **bullet points**  
- Uses **ML** to improve ATS scoring & suggestions  
- Highlights weak phrases directly in the **PDF**  
- Exposes a clean **API** used by an interactive **web UI** (Tailwind + Framer Motion)

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ compute.py          # compute_ats_scores() â€“ ATS scoring engine
â”‚   â”œâ”€â”€ helpers.py          # clean_text, extract_bullets, weak_phrases, etc.
â”‚   â”œâ”€â”€ suggestions.py      # generate_suggestions() â€“ rule + ML hybrid
â”‚   â”œâ”€â”€ utils.py            # extract_texts(), highlight_pdf(), helpers
â”‚   â”œâ”€â”€ predict.py          # ML model & multi-label binarizer (mlb, model)
â”‚   â””â”€â”€ synthetic_data.py   # Synthetic ATS dataset generator (optional)
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ views.py            # ApiResponsev1 â€“ /api/analyze implementation
â”‚   â”œâ”€â”€ db.py               # collection (if using a DB)
â”‚   â””â”€â”€ exceptions.py       # ApiResponseError wrapper
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html           # Layout with Tailwind + React + Framer Motion CDNs
â”‚   â””â”€â”€ index.html          # Resume analyzer UI (Jinja2)
â”‚
â”œâ”€â”€ static/                 # (optional) Custom JS / CSS if you extract them
â”‚
â”œâ”€â”€ README.md               # â† this file
â””â”€â”€ requirements.txt
```

> The exact filenames may differ slightly in your project â€“ adjust paths as needed.

---

## ğŸš€ Features

### âœ… Backend

- Built around an async API class: `ApiResponsev1`
- Accepts either:
  - `resume_text` (plain text), or  
  - `resume_file` (PDF upload)
- Optionally accepts `jd_text` (job description) for keywordâ€‘aware scoring
- Uses:
  - `extract_texts()` to read PDF
  - `clean_text()` to normalize content
  - `extract_bullets()` to detect bullet points
  - `weak_phrases()` to find vague / weak wording
  - `compute_ats_scores()` to compute ATS metrics & overall score
  - `generate_suggestions()` to produce humanâ€‘readable guidance
  - `highlight_pdf()` to create a highlighted PDF (weak phrases + bullets)
- Automatically **deletes temp files** after each request

### âœ… ATS Scoring

`compute_ats_scores(resume_text, jd_text="")` returns a dictionary with:

- `final_score` â€“ overall ATS score (0â€“100)
- `section_score` â€“ coverage of key sections (Experience, Education, Skills, Summary, etc.)
- `keyword_score` â€“ overlap between resume and job description
- `action_score` â€“ share of bullets starting with strong action verbs
- `metric_score` â€“ share of bullets containing measurable numbers / %, / $
- `length_score` â€“ effectiveness of resume length & density
- Additional metadata:
  - `word_count`
  - `bullets_count`
  - `section_found`
  - `bullets`

### âœ… Suggestions (Rule + ML Hybrid)

`generate_suggestions(analysis, weak_phrases, has_jd)` uses:

- ATS scores from `analysis`
- List of weak phrases found
- Info on whether a JD was provided
- Optionally ML classifier (if wired in) to prioritise suggestion categories

Example suggestions:

- â€œMissing important sections: Experience, Skillsâ€
- â€œLow keyword match â€” tailor resume more closely to the job description.â€
- â€œMore bullet points should start with action verbs.â€
- â€œAdd more measurable achievements (%, $, numbers).â€
- â€œWeak phrases detected: responsible for, worked on, assisted withâ€

### âœ… ML Engine

The project is designed to support an MLâ€‘based ATS score & suggestion engine using scikitâ€‘learn:

- `synthetic_data.py` (or similar) can generate thousands of synthetic resumes with labels
- `predict.py` holds:
  - `model` â€“ scikitâ€‘learn pipeline (e.g. TFâ€‘IDF + Ridge/Logistic Regression)
  - `mlb` â€“ MultiLabelBinarizer for suggestion categories
- ML models can:
  - Predict ATS score directly
  - Predict suggestion categories (e.g. missing sections, weak metrics, etc.)
  - Be retrained using synthetic or real datasets

---

## ğŸŒ API Design

### Endpoint: `POST /api/analyze`

**Request (multipart/form-data):**

- `resume_text` (optional, string)
- `resume_file` (optional, file â€“ PDF)
- `jd_text` (optional, string)

At least one of `resume_text` or `resume_file` **must** be present.

**Response (JSON):**

```jsonc
{
  "compute": {
    "final_score": 78.5,
    "section_score": 90.0,
    "keyword_score": 65.0,
    "action_score": 70.0,
    "metric_score": 40.0,
    "length_score": 85.0,
    "word_count": 546,
    "bullets_count": 12,
    "section_found": {
      "Summary": true,
      "Experience": true,
      "Education": true,
      "Skills": false
    },
    "bullets": [
      "Led migration of legacy system to microservices architecture...",
      "Improved query performance by 45% by optimising indexes..."
    ]
  },
  "suggestions": [
    "Missing important sections: Skills",
    "Add more measurable achievements (%, $, numbers).",
    "Low keyword match â€” tailor resume more closely to the job description."
  ],
  "weak_phrases": [
    { "phrase": "responsible for", "start": 123, "end": 137, "snippet": "..." }
  ],
  "bullets": [
    "Led migration of legacy system...",
    "Improved performance by 45%..."
  ],
  "file_out": "abcd-1234_highlighted.pdf"
}
```

---

## ğŸ§© Backend: `ApiResponsev1` Flow

Simplified logic:

```python
class ApiResponsev1:
    async def analyse(self, request: Request) -> Response:
        temp_files = []

        try:
            if request.method != "POST":
                raise ApiResponseError(details="Method Not Allowed", status=404)

            form = await request.form()
            resume_text = form.get("resume_text") or ""
            jd_text = form.get("jd_text") or ""
            file = form.get("resume_file")

            # CASE 1: file upload
            if file and hasattr(file, "filename") and file.filename:
                file_id, file_path, file_name = await self._process_file(file)
                temp_files.append(file_path)

                extracted_text = extract_texts(file_path)
                resume_text = extracted_text

                output = self._build_result(
                    resume_text=resume_text,
                    jd_text=jd_text,
                    file_path=file_path,
                    file_name=file_name,
                )

                if output.get("file_out"):
                    temp_files.append(os.path.join(self.UPLOAD_DIR, output["file_out"]))

            # CASE 2: text only
            elif resume_text.strip():
                output = self._build_result(
                    resume_text=resume_text,
                    jd_text=jd_text,
                    file_path=None,
                    file_name=None,
                )

            else:
                raise ApiResponseError(
                    details="No resume text or file provided", status=400
                )

            return JsonResponse(content=output, status=200)

        except ApiResponseError as e:
            return JsonResponse(content={"error": e.details}, status=e.status, headers=e.headers)

        except Exception:
            import traceback
            traceback.print_exc()
            return JsonResponse(content={"error": "Internal Server Error"}, status=500)

        finally:
            # Delete temp files
            for path in temp_files:
                try:
                    if os.path.exists(path):
                        os.remove(path)
                except Exception:
                    traceback.print_exc()
```

---

## ğŸ¨ Frontend Overview

The frontend is implemented with:

- **Jinja2** templates (compatible with Flask/FastAPI/Aquilify)
- **Tailwind CSS (CDN)** for styling
- **React + Framer Motion (CDN)** for animated score ring
- **Metaâ€‘/portalâ€‘style UI** inspired by official government / ITS portals
- Lightâ€‘mode only, responsive layout

### Key UX Features

- **Drag & drop** PDF upload
- Live **file name preview**
- API call via `fetch("/api/analyze")` with `FormData`
- **Loading spinner overlay** while the backend works
- **Score widget** with animated circular gauge
- Tabbed panels:
  - Scores
  - Suggestions
  - Sections & Bullets
  - ML Details

Example submission (using JS):

```js
const formData = new FormData();
formData.append("resume_text", resumeTextArea.value);
formData.append("jd_text", jdTextArea.value);
if (fileInput.files[0]) {
  formData.append("resume_file", fileInput.files[0]);
}

const res = await fetch("/api/analyze", {
  method: "POST",
  body: formData
});
const data = await res.json();
renderResults(data);
```

---

## ğŸ”¬ Core Analysis Functions

### `clean_text(text: str) -> str`

- Lowercases
- Normalizes whitespace
- Strips control characters & noise
- Optionally handles special unicode bullets / ligatures

### `extract_bullets(text: str) -> List[str>`

- Detects bullets even when PDF is flattened into a **single line**
- Handles Unicode bullets such as `â€¢`, `â–ª`, `â€“`, etc.
- Supports:
  - Inline bullets (`â€¦ â€¢ Managed 25 volunteers. â€¢ Maintained records â€¦`)
  - Multiline bullets with indentation

Example approach for inline bullets:

```python
pattern = re.compile(
    r"(?:^| )"
    r"[â€¢\u2022\u2023\u25CF\u25AA\u25E6\u00B7]"
    r"\s*(?P<item>[^â€¢\u2022\u2023\u25CF\u25AA\u25E6\u00B7]+)"
)
```

### `weak_phrases(text: str) -> List[dict]`

- Scans the resume for weak phrases such as:
  - â€œresponsible forâ€
  - â€œworked onâ€
  - â€œhelped withâ€
  - â€œparticipated inâ€
  - â€œvarious tasksâ€
- Uses regex with word boundaries and flexible whitespace
- Returns:
  - `phrase`
  - `start` / `end` indices
  - `snippet` for context

---

## ğŸ§ª Synthetic Dataset (Optional)

The project can include a script like `synthetic_data.py` that:

- Generates ~5,000 synthetic resumes
- Varies:
  - strength of action verbs
  - presence of metrics
  - coverage of sections
  - keyword alignment
- Computes ruleâ€‘based ATS scores as labels
- Adds noise to simulate human scoring
- Saves to `synthetic_ats_dataset.csv`

Used to train:

- ATS scoring regression model
- Suggestion multiâ€‘label classifier

---

## âš™ï¸ Installation & Setup

### 1. Clone the repo

```bash
git clone https://github.com/axiomchronicles/resume-analyzer.git
cd resume-analyzer
```

### 2. Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

Typical `requirements.txt` could include:

```txt
aquilify
fastapi
uvicorn
pymupdf
scikit-learn
pandas
numpy
python-docx
jinja2
reportlab
```

Adjust based on your actual project.

### 4. Run the backend

Depending on how Aquilify is wired (or if using FastAPI / Starlette):

```bash
uvicorn main:app --reload
```

or (if you use Aquilifyâ€™s CLI):

```bash
aquilify run
```

### 5. Open the UI

- Navigate to `http://localhost:8000/` (or the port you configured)
- Paste or upload a resume
- Optionally paste a job description
- Click **Run Analysis**

You should see:

- ATS score ring animate
- Detailed subâ€‘scores
- Suggestions
- Extracted bullets
- Weak phrases badges
- Optionally a link to download the highlighted PDF (if you expose it)

---

## ğŸ“š Possible Extensions

- Add **authentication** and store user analyses
- Export full **PDF report** summarising the analysis
- Add **multiâ€‘language** support (English + others)
- Integrate a **large language model** for richer, naturalâ€‘language feedback
- Deploy the app using:
  - Docker
  - Render / Railway / Fly.io / AWS / Azure

---

## ğŸ™‹ FAQ

**Q: Does this exactly match real ATS systems?**  
A: No. It simulates common ATS heuristics (sections, keywords, metrics), and uses ML to improve scoring, but itâ€™s a learning / demo project, not tied to any proprietary ATS.

**Q: Can I plug in my own ML model?**  
A: Yes. As long as your model exposes a `predict()` or `predict_proba()` interface (and you adapt `predict.py`), you can swap out the core model.

**Q: Can I use only ruleâ€‘based scoring without ML?**  
A: Absolutely. `compute_ats_scores()` is fully ruleâ€‘based. ML is optional and layered on top.

---

## ğŸ’¡ Credits & Acknowledgements

This project blends concepts from:

- Natural Language Processing
- Applied Machine Learning
- Web backend APIs
- Modern frontend UIs

Itâ€™s ideal as a **college project**, **portfolio piece**, or **internal tool** to understand how realâ€‘world resume screening tools work.

---

Happy hacking & resumeâ€‘optimizing! ğŸš€
